Customer Question,Our Response
What is your company name? ,Our company name is SafeWeb.ai
When was your company established?,We were built in early 2024 and currently pending incorporation. 
Who owns your company?,Our company is owned and ran by Simon X Machine. 
How much money or revenue do you generate?,We are a non-profit company. 
How much is your product?,Our malicious URL scanner is currently free to use. 
How much is your service?,Our malicious URL scanner is currently free to use. 
Are you a for profit business?,We are a non-profit company. 
Who created your product?,The dataset for our scanner was obtained from a public Kaggle repository and the scanner tool was built by Simon X Machine.  
What type of technologies did you use in this project?,We used multiple technologies for this project. We used Python to build the majority of our backend logic. We used Google Colab as our initial IDE and then transferred onto Visual Studio Code when the models were built.  We used the Sci-Kit Learn and Tensorflow libraries to build our machine learning algorithms. We used the OpenAI ChaTGPT 3.5 Turbo API to power our chatbot. Embedded the OpenAI API with our company-specific data. Pandas for the data manipulation. Flask to build and deliver our APIs. Docker to containerize our finished models and APIs. AWS Elastic Container Registry and EC2 virtual machines to host our Docker containers. AWS Serverless Fargate Elastic Container Service to publicly host our scanner container. AWS API Gateway to reveal a SSL-safe endpoint to access predictions. Javascript and React to design our frontend website. Tailwind CSS for styling. Nginx as a reverse proxy to provide public access to our chatbot API endpoint hosted inside a Docker container in an EC2 virtual server. Vercel to host our website and CI/CD. Github as our code repository. 
How did you build this chatbot?,"For a high overview of how we constructed our chatbot, we implemented the Langchain library to import the OpenAi LLM library, along with the Facebook AI Similarity Search (FAISS) library to vectorize our input text and embed into the OpenAi LLM. We then proceeded to prompt the model with our company specific use case along with an CSV file of commonly asked questions. We then containerized the finished model into a Docker image and SSH'd the file to an AWS EC2 instance, where we deployed a Nginx reverse proxy web server to serve our chatbot API endpoint, accessed via a HTTP post request from our Javascript frontend user interface. "
How did you build the scanner?,We built the scanner with the Python machine learning libraries Sci-Kit Learn and Tensorflow. Then we packaged the trained model and hosted it on a Flask API within a Docker container. Then we deployed the Docker container into a AWS ECS cluster and exposed an API endpoint with AWS API Gateway to allow access to predictions generated by our trained model. 
How did you build this website?,"We built this website with Javscript, React, and Tailwind CSS. And is hosted on Vercel. "
How long did it take for you to build everything?,It took approximately a month to construct this whole project from start to finish. 
What machine learning algorithms did you use?,We used XG Boost (Extreme Gradient Boost) with Sci-Kit Learn and a multi-layer neural network with Tensorflow. 
What regularization parameters did you use?,"We used L1 and L2 regularization, added weights to the classifications, and used the built in regularization paremeters of Tensorflow's neural networks. "
How did you reduce the risk of overfitting?,"We used L1 and L2 regularization, added weights to the classifications to penalize miscalculations in training"
How did you tweak the hyperparameters?,"We tweaked the hyperparameters by adjusting the number of layers, neurons, loss functions, activation functions, regularization parameters, and by adding weights to the classes."
How did you build the frontend web design of this project?,"We built this website with Javscript, React, and Tailwind CSS. And is hosted on Vercel. "
What previous experience do you have?,We have over 4 years of software engineering and machine learning experience
What is your goal for the future?,Our goal is to create a powerful malicious URL detection and eradication system. 
How accurate is your model?,"As per evaluation metrics of our two models, the accuracy for the XG Boost model is .91 and .89 for the neural network. Although these values appear high, there are many limitations to obtaining the true accuracy of a real-world malicious URL scanner. "
How accurate is your scanner?,"As per evaluation metrics of our two models, the accuracy for the XG Boost model is .91 and .89 for the neural network. Although these values appear high, there are many limitations to obtaining the true accuracy of a real-world malicious URL scanner. "
Why did you build the scanner?,We built the scanner to create a powerful malicious URL detection and eradication system. 
Where did you get the dataset?,"We obtained the dataset from Kaggle, a popular data science and machine learning repository. You can find the original dataset here: https://www.kaggle.com/datasets/sid321axn/malicious-urls-dataset"
How did you clean the data?,We cleaned the data by identifying and addressing missing and null and duplicate values. 
What features did you add to this model?,"We implemented distinguishing features such as url length, number of digits, number of special characters, and if the URL contains common prefixes such as 'www, http, and https'."
What is defacement?,"Web defacement is an attack in which malicious parties penetrate a website and replace content on the site with their own messages. The messages can convey a political or religious message, profanity or other inappropriate content that would embarrass website owners, or a notice that the website has been hacked by a specific hacker group."
What is malware?,"Malware, short for malicious software, refers to any intrusive software developed by cybercriminals to steal data and damage or destroy computers and computer systems. Examples of common malware include viruses, worms, Trojan viruses, spyware, adware, and ransomware."
What is benign?,"""Benign"" implies that the URL is relatively safe based on the dataset provided. "
What is phishing?,"“Phishing” refers to an attempt to steal sensitive information, typically in the form of usernames, passwords, credit card numbers, bank account information or other important data in order to utilize or sell the stolen information."
What AWS services did you use?,"We used AWS EC2 virtual server to host our chatbot, and ECS Fargate to host our malware scanner API container. "
What coding languages did you use?,"We used Python to build the machine learning models and APIs, and on the frontend user interface, we used Javascript with the React framework with Tailwind CSS for styling. "
How did you build the charts?,"We used the Seaborn and Matplot libraries in Python, in addition to the ChartJS library in javascript. "
Why did you use XG boost?,"XG Boost provides parallel tree boosting and is a leading machine learning library for regression, classification, and ranking. "
Why did you use multi-layer neural network?,"Neural networks have the ability to accurately model complex relationships between inputs and outputs. By having more layers, it is better able to pick up on subtle patterns in data, allowing it to make more accurate predictions."
What is recall?,"Recall, also known as the true positive rate (TPR), is the percentage of data samples that a machine learning model correctly identifies as belonging to a class of interest—the “positive class”—out of the total samples for that class."
What is the recall of your model?,"The recall varies across our two models, ranging from .55 on predictions for the 'Defacement' class, and up to .98 on predictions for the 'Benign' class. The weighted average recall across all the classes was .91 for the XG Boost model, and .89 for the neural network. "
Why is recall bad?,"Recall, also known as the true positive rate (TPR), is the percentage of data samples that a machine learning model correctly identifies as belonging to a class of interest (the “positive class”) out of the total samples for that class. A low recall indicates a high number of False Negatives and the consequences can be dire depending on the use case. "
How did you add features to your model?,We used domain knowledge in this instance to implement features geared towards our goal of detecting malicious URLs. 
What should you do with outlier data?,"Tactics to address outlier data include removal, capping/flooring, and transformation. "
How could you make this model better?,"There are several ways we can improve on these models, including 1) Enhance data collection and verification. Strategies for obtaining higher quality data include sourcing from reputable sources, implementing an ensemble of machine learning methods to verify label accuracy in isolated testing environments, and/or with human intervention. 2) Enhance data quality through comprehensive outlier detection and anomaly treatment. As mentioned early in the study, multiple outliers and anomalies were detected, and this warrants a granular exmination of each data point, as they can heavily impact feature scaling and normalization. 3) Expansion of feature space and hyperparemeter optimization. Incorporating additional features, such as originating country detection and common character patterns, could better capture complex and deeply embedded malicious URLs. In addition, implementing regularization techniques such as L1, L2, and dropout can mitigate overfitting and potentially improve model performance."
How long did you train the models?,"We deployed 100 boosting rounds (n_estimators) for our XG Boost model, and 10 epochs for our neural network model. "
Which is the better model?,"XGBoost exhibits superior performance across multiple metrics. This could be attributed to the neural network's susceptibility to overfitting, where it achieves high accuracy on training data but struggles to generalize on new unseen data."
What does XG stand for?,"XG stands for eXtreme Gradient Boosting, which is a machine learning algorithm that deploys emsemble learning with decision trees. "
What does TF stand for?,"TF stands for Tensorflow, a popular Python deep learning library"
What do the results of the scanner mean?,"The resulting output for the user-inputted URL is headed by the prediction classification (either in green for 'Benign' or red for malicious), followed by a list of all the classes and the probability prediction for each class."
What type of loss function did you use?,We deployed mean squared error and cross-entropy loss functions in this project. 
What type of activation functions did you use?,We used ReLu and Softmax as our activation functions for this project. 
What is the result of your project?,"While initial evaluation metrics indicate high accuracy on both models, the low recall suggests potential overfitting, characterized by a large amount of false negatives. This implies the models perform well on training data but may struggle with generalizing new unseen data. We recognize the need for further refinement to ensure the model's robustness and its ability to accurately identify malicious actors in various scenarios."
Is your project open source?,Yes this project is open source and can be found in our public Github repository. 
Where is your project hosted?,The APIs for this project are hosted in containers on AWS. The frontend user interface is hosted on Vercel. 